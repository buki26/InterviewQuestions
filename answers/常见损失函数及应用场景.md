# 常见损失函数及应用场景

损失函数用来评价模型的预测值和真实值不一样的程度。

一般来说，我们在进行机器学习任务时，使用的每一个算法都有一个目标函数，算法便是对这个目标函数进行优化，特别是在分类或者回归任务中，便是使用损失函数（Loss Function）作为其目标函数，又称为代价函数(Cost Function)。

损失函数分为经验风险损失函数和结构风险损失函数。经验风险损失函数指预测结果和实际结果的差别，结构风险损失函数是指经验风险损失函数加上正则项。

通俗的讲，可以把损失函数或代价函数理解为，一个反应了模型预测值与真实值之间差异的函数，而我们训练模型的过程就是最小化这个代价函数的过程。

损失通常使用![](<http://latex.codecogs.com/gif.latex?L(Y,f(x))>)来表示，损失函数越小，模型的性能就越好。
   设总有![](http://latex.codecogs.com/gif.latex?N)个样本的样本集为![](<http://latex.codecogs.com/gif.latex?(X,Y)=(x_{i},y_{i})>)，![](<http://latex.codecogs.com/gif.latex?\hat{y}_{i}=f(x_{i})>)，![](http://latex.codecogs.com/gif.latex?y_{i})是真实值，![](http://latex.codecogs.com/gif.latex?\hat{y})是预测值，![](http://latex.codecogs.com/gif.latex?f)为分类或者回归函数。
那么总的损失函数为：
![](<http://latex.codecogs.com/gif.latex?L=\sum_{i=1}^{N}l(y_{i},\hat{y}_{i})>)

**几种基础的损失函数**

1. 0-1 损失函数

   ![](https://github.com/buki26/image/blob/master/0-1%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.jpg)

   这个定义太过严格，如果真实值为 1，预测值为 0.999，那么预测应该正确，但是上述定义显然是判定为预测错误，那么可以进行改进为 Perceptron Loss。

2. Perceptron Loss（感知损失）
   ![](https://github.com/buki26/image/blob/master/%E6%84%9F%E7%9F%A5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.jpg)
   另外还有 Hinge Loss 和 Square Loss 等，都属于比较基础的 loss 函数。

## 常用的损失函数

首先损失函数的求解方法通常是梯度下降法等。

1. 最大似然估计（MLE）
2. 贝叶斯估计（Bayesian）
3. 最大后验概率（MAP）

   > 比 MLE 多一个正则项
   >
   > > 正则项:
   > > ![](http://latex.codecogs.com/gif.latex?\lambda\left|\theta\right|_{F}^{2})
   > > θ 是模型参数，λ 是超参数
   > > 因为目标是最小化目标函数，所以调节 λ 相当于调整 θ 的取值空间，λ 越大，θ 取值空间越小，从而防止过拟合。
   >
   > 对于回归问题，用 RMSE，即均方误差：
   > ![](<http://latex.codecogs.com/gif.latex?\sum_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2}>)
   > 对于分类问题，用交叉熵：
   > ![](<http://latex.codecogs.com/gif.latex?\sum_{i=1}^{n}y_{i}log\hat{y}_{i}+(1-y_{i})log(1-\hat{y}_{i})>)
   > ￼

![](http://latex.codecogs.com/gif.latex?)
